{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f7b5c0d-a15b-4cbd-9850-ee488c855a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# worked but not epidimological\n",
    "prompt = \"\"\"\n",
    "INSTRUCTIONS:\n",
    "Create ONE concise, snake_case label for the that describes **all** of the following values as a single category.\n",
    "Return only the label and nothing else. Note it's not allowed to output any input values that was provided, instead you need to create new label.\n",
    "\n",
    "Input: oui, non, yes, no, true, false  \n",
    "Output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ede4875-eb17-4594-873c-05491081d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are an epidemiology data steward.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "Create ONE concise, snake_case epidemiological label that describes **all** of the inputted values.\n",
    "Return only the label—no extra text.  \n",
    "Do **not** reuse any of the input words; invent a new identifier.\n",
    "\n",
    "Task  \n",
    "Input: 0C101DE5RTQ2, E15R0T0CQ52D, RC18E0T03Q2D, 03QRTED050C0, 02RE0QT1C4D1  \n",
    "Output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7c10d4-a610-4890-8f33-60442f6b313f",
   "metadata": {},
   "outputs": [],
   "source": [
    "System: You are an epidemiology data steward.\n",
    "User:\n",
    "INSTRUCTIONS:\n",
    "• You’ll get a comma-separated list of arbitrary tokens (IDs, dates, names, etc.).\n",
    "• Invent exactly one concise snake_case label summarizing the shared epidemiologic context.\n",
    "• Do NOT copy or overlap any part of the input tokens.\n",
    "• Return only that one label, no extra text.\n",
    "\n",
    "Example 1:\n",
    "Input: 0C101DE5RTQ2, E15R0T0CQ52D, RC18E0T03Q2D, 03QRTED050C0, 02RE0QT1C4D1\n",
    "Output: viral_spread_pattern\n",
    "\n",
    "Example 2:\n",
    "Input: 2025-06-01, 2025-06-02, 2025-06-03, 2025-06-04, 2025-06-05\n",
    "Output: short_term_incidence\n",
    "\n",
    "Now it’s your turn:\n",
    "Input: <your_values_here>\n",
    "Output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e619943-79c6-4fef-891c-bb0bb1e40ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt:\n",
      " \n",
      "System: You are an epidemiology data steward.\n",
      "\n",
      "INSTRUCTIONS:\n",
      "• You’ll get a comma-separated list of arbitrary tokens (IDs, dates, names, etc.).\n",
      "• Invent exactly one concise snake_case label summarizing the shared epidemiologic context.\n",
      "• Do NOT copy or overlap any part of the input tokens.\n",
      "• Return only that one label, no extra text.\n",
      "\n",
      "Example 1:\n",
      "Input: 0C101DE5RTQ2, E15R0T0CQ52D, RC18E0T03Q2D, 03QRTED050C0, 02RE0QT1C4D1\n",
      "Output: viral_spread_pattern\n",
      "\n",
      "Example 2:\n",
      "Input: 2025-06-01, 2025-06-02, 2025-06-03, 2025-06-04, 2025-06-05\n",
      "Output: short_term_incidence\n",
      "\n",
      "Now it’s your turn:\n",
      "Input: non, oui, true, false, unknown\n",
      "Output:\n",
      "\n",
      "\n",
      "Response:\n",
      " \n",
      "System: You are an epidemiology data steward.\n",
      "\n",
      "INSTRUCTIONS:\n",
      "• You’ll get a comma-separated list of arbitrary tokens (IDs, dates, names, etc.).\n",
      "• Invent exactly one concise snake_case label summarizing the shared epidemiologic context.\n",
      "• Do NOT copy or overlap any part of the input tokens.\n",
      "• Return only that one label, no extra text.\n",
      "\n",
      "Example 1:\n",
      "Input: 0C101DE5RTQ2, E15R0T0CQ52D, RC18E0T03Q2D, 03QRTED050C0, 02RE0QT1C4D1\n",
      "Output: viral_spread_pattern\n",
      "\n",
      "Example 2:\n",
      "Input: 2025-06-01, 2025-06-02, 2025-06-03, 2025-06-04, 2025-06-05\n",
      "Output: short_term_incidence\n",
      "\n",
      "Now it’s your turn:\n",
      "Input: non, oui, true, false, unknown\n",
      "Output:\n",
      "user_choice\n"
     ]
    }
   ],
   "source": [
    "# 4. Single-shot prompt and response\n",
    "prompt = \"\"\"\n",
    "System: You are an epidemiology data steward.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "• You’ll get a comma-separated list of arbitrary tokens (IDs, dates, names, etc.).\n",
    "• Invent exactly one concise snake_case label summarizing the shared epidemiologic context.\n",
    "• Do NOT copy or overlap any part of the input tokens.\n",
    "• Return only that one label, no extra text.\n",
    "\n",
    "Example 1:\n",
    "Input: 0C101DE5RTQ2, E15R0T0CQ52D, RC18E0T03Q2D, 03QRTED050C0, 02RE0QT1C4D1\n",
    "Output: viral_spread_pattern\n",
    "\n",
    "Example 2:\n",
    "Input: 2025-06-01, 2025-06-02, 2025-06-03, 2025-06-04, 2025-06-05\n",
    "Output: short_term_incidence\n",
    "\n",
    "Now it’s your turn:\n",
    "Input: non, oui, true, false, unknown\n",
    "Output:\n",
    "\"\"\"\n",
    "response = generate_response(prompt, tokenizer, model)\n",
    "print(\"Prompt:\\n\", prompt)\n",
    "print(\"\\nResponse:\\n\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94888d72-9c03-44d1-a0e8-f2f013a4043a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Running LLaMA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f1a0732-74ea-4405-8c6e-6f19ecd79015",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (1724933310.py, line 2)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mInput: 0C101DE5RTQ2, E15R0T0CQ52D, RC18E0T03Q2D, 03QRTED050C0, 02RE0QT1C4D1\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "Example 1:\n",
    "Input: 0C101DE5RTQ2, E15R0T0CQ52D, RC18E0T03Q2D, 03QRTED050C0, 02RE0QT1C4D1\n",
    "Output: viral_spread_pattern\n",
    "\n",
    "Example 2:\n",
    "Input: 2025-06-01, 2025-06-02, 2025-06-03, 2025-06-04, 2025-06-05\n",
    "Output: short_term_incidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de53ed9a-aba2-4802-afc2-206475d0ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "- label should be from epidimiological set and make sense\n",
    "\n",
    "\n",
    "   • If one existing label is a clear semantic fit, output *that* label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "aac6dbf9-9ab7-4412-8671-9981c2a48a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## DO NOT USE\n",
    "prompt = \"\"\"\n",
    "You are an epidemiology data steward.\n",
    "\n",
    "TASK\n",
    "1. You will receive:\n",
    "   • a comma-separated list of *input tokens* (IDs, dates, names, free text, etc.).\n",
    "   • a comma-separated *existing_label_list* (may be empty).\n",
    "\n",
    "2. Produce **exactly one** snake_case label **and nothing else** or take :\n",
    "   • If there is existing label that matches with the input, then output that label.\n",
    "   • Otherwise output: NEWLABEL:<concise_snake_case_label>  \n",
    "     – invent 1 word label  \n",
    "     – generated label should not include any input value\n",
    "     - label should be generated from epidimiological perspective and make sense for the human\n",
    "\n",
    "Output format: the label string only (either an existing label or the NEWLABEL:… form).\n",
    "\n",
    "existing_label_list: [\"answer_status\"],\n",
    "Input: \"Oui\", \"Non\", \"True\", \"False\", \"Yes\", \"No\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d12827f5-e09c-4b8e-acf1-540e36b4f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "System: You are an epidemiology data steward.\n",
    "\n",
    "INSTRUCTIONS:\n",
    "• You’ll get a comma-separated list of arbitrary tokens (IDs, dates, names, etc.).\n",
    "• Invent exactly one concise snake_case label summarizing the shared epidemiologic context.\n",
    "• Do NOT copy or overlap any part of the input tokens.\n",
    "• Return only that one label, no extra text.\n",
    "\n",
    "Now it’s your turn:\n",
    "Input: [\"0C101DE5RTQ2\", \"E15R0T0CQ52D\", \"RC18E0T03Q2D\", \"03QRTED050C0\", \"02RE0QT1C4D1\"]\n",
    "Output:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "a870ad65-df21-4efb-bb52-12fb56f37542",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3.1:8b-instruct-q8_0', 'created_at': '2025-06-19T10:09:08.190469047Z', 'response': 'vaccine_lot_numbers', 'done': True, 'done_reason': 'stop', 'context': [128006, 882, 128007, 1432, 2374, 25, 1472, 527, 459, 62057, 2508, 828, 69606, 382, 691, 93631, 512, 6806, 1472, 4805, 636, 264, 32783, 73792, 1160, 315, 25142, 11460, 320, 31566, 11, 13003, 11, 5144, 11, 5099, 13, 4390, 6806, 93258, 7041, 832, 64694, 26332, 19640, 2440, 29385, 4954, 279, 6222, 62057, 39227, 2317, 627, 6806, 3234, 4276, 3048, 477, 28347, 904, 961, 315, 279, 1988, 11460, 627, 6806, 3494, 1193, 430, 832, 2440, 11, 912, 5066, 1495, 382, 7184, 433, 753, 701, 2543, 512, 2566, 25, 4482, 15, 34, 4645, 1170, 20, 5463, 48, 17, 498, 330, 36, 868, 49, 15, 51, 15, 34, 48, 4103, 35, 498, 330, 7532, 972, 36, 15, 51, 2839, 48, 17, 35, 498, 330, 2839, 48, 5463, 1507, 16193, 34, 15, 498, 330, 2437, 793, 15, 44778, 16, 34, 19, 35, 16, 7171, 5207, 512, 128009, 128006, 78191, 128007, 271, 85, 89121, 92949, 34064], 'total_duration': 116960849, 'load_duration': 50118781, 'prompt_eval_count': 147, 'prompt_eval_duration': 1904234, 'eval_count': 5, 'eval_duration': 63581517}\n",
      "vaccine_lot_numbers\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "resp = requests.post(\n",
    "    \"http://localhost:11434/api/generate\",\n",
    "    json={\n",
    "        \"model\":   \"llama3.1:8b-instruct-q8_0\",\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 120,\n",
    "        \"stream\":  False       # ← disable NDJSON streaming\n",
    "    }\n",
    ")\n",
    "\n",
    "# now this is valid JSON:\n",
    "data = resp.json()\n",
    "print(data)\n",
    "print(data[\"response\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe0a60d-d3d4-4592-8f1e-b1ee8f42b3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "logprobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7cd37b69-814d-41fb-90af-1cc9136e38b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 2 column 1 (char 112)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/archetype/lib/python3.11/site-packages/requests/models.py:963\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson.loads(\u001b[38;5;28mself\u001b[39m.content.decode(encoding), **kwargs)\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mUnicodeDecodeError\u001b[39;00m:\n\u001b[32m    965\u001b[39m     \u001b[38;5;66;03m# Wrong UTF codec detected; usually because it's not UTF-8\u001b[39;00m\n\u001b[32m    966\u001b[39m     \u001b[38;5;66;03m# but some other 8-bit codec.  This is an RFC violation,\u001b[39;00m\n\u001b[32m    967\u001b[39m     \u001b[38;5;66;03m# and the server didn't bother to tell us what codec *was*\u001b[39;00m\n\u001b[32m    968\u001b[39m     \u001b[38;5;66;03m# used.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/archetype/lib/python3.11/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_decoder.decode(s)\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/archetype/lib/python3.11/json/decoder.py:340\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[32m--> \u001b[39m\u001b[32m340\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExtra data\u001b[39m\u001b[33m\"\u001b[39m, s, end)\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Extra data: line 2 column 1 (char 112)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[154]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      1\u001b[39m resp = requests.post(\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mhttp://localhost:11434/api/generate\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# llama_cpp.server port\u001b[39;00m\n\u001b[32m      3\u001b[39m     headers={\u001b[33m\"\u001b[39m\u001b[33mContent-Type\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     timeout=\u001b[32m60\u001b[39m\n\u001b[32m     12\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m probs = resp.json()[\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mlogprobs\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mtop_logprobs\u001b[39m\u001b[33m\"\u001b[39m][\u001b[32m0\u001b[39m]\n\u001b[32m     15\u001b[39m label, p = \u001b[38;5;28mmax\u001b[39m(probs.items(), key=\u001b[38;5;28;01mlambda\u001b[39;00m kv: kv[\u001b[32m1\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/archetype/lib/python3.11/site-packages/requests/models.py:971\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    969\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m    970\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m971\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n\u001b[32m    973\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    974\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m complexjson.loads(\u001b[38;5;28mself\u001b[39m.text, **kwargs)\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Extra data: line 2 column 1 (char 112)"
     ]
    }
   ],
   "source": [
    "resp = requests.post(\n",
    "    \"http://localhost:11434/api/generate\",  # llama_cpp.server port\n",
    "    headers={\"Content-Type\": \"application/json\"},\n",
    "    json={\n",
    "        \"model\": \"llama3.1:8b-instruct-q8_0\",\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 1,\n",
    "        \"temperature\": 0,\n",
    "        \"logprobs\": 10          # <— token-probabilities!\n",
    "    },\n",
    "    timeout=60\n",
    ")\n",
    "\n",
    "probs = resp.json()[\"choices\"][0][\"logprobs\"][\"top_logprobs\"][0]\n",
    "label, p = max(probs.items(), key=lambda kv: kv[1])  # pick highest-prob label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ffdb8b5-e3c9-467e-bc3d-31a569e86586",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
