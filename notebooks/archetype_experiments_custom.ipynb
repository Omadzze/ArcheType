{
 "cells": [
  {
   "cell_type": "code",
   "id": "584962c4-a8c7-4cdf-9594-a0626a9909f3",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-07-22T12:59:35.176504Z",
     "start_time": "2025-07-22T12:59:35.172389Z"
    },
    "tags": [
     "parameters"
    ]
   },
   "source": [
    "TRAIN_SCRIPT_ALPACA = \"/home/omadbek/projects/alpaca/train.py\"\n",
    "# weights of alpaca\n",
    "BASE_MODEL_ALPACA_PATH = (\n",
    "    \"/home/omadbek/.cache/huggingface/hub/\"\n",
    "    \"models--chavinlo--alpaca-native/\"\n",
    "    \"snapshots/3bf09cbff2fbd92d7d88a0f70ba24fca372befdf\"\n",
    ")\n",
    "\n",
    "CUSTOM_DATA_PATH = \"/home/omadbek/projects/ArcheType/fine_tuned_data/full_train_finetune.json\"\n",
    "\n",
    "FINE_TUNED_WEIGHTS_PATH = \"/home/omadbek/projects/alpaca/outputs\"\n",
    "\n",
    "PAPERMILL_ROOT = \"/home/omadbek/projects/ArcheType/papermill_notebooks\"\n",
    "\n",
    "MODEL_NAME = \"llama\" #llama, flan-ul2, flan-t5, flan-t5-xxl\", alpaca-fine-tuned\n",
    "\n",
    "SHERLOCK_PATH  = \"/home/omadbek/projects/Sherlock\""
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-07-22T12:59:33.921843Z",
     "start_time": "2025-07-22T12:59:33.225613Z"
    }
   },
   "cell_type": "code",
   "outputs": [],
   "execution_count": 1,
   "source": [
    "import os\n",
    "import json\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from pathlib import Path\n",
    "import shutil"
   ],
   "id": "1315722a-dde4-452a-99ec-90a242ba3648"
  },
  {
   "cell_type": "code",
   "id": "0d4eb691-8996-4159-983d-5261bc938b0d",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-07-22T12:59:36.197649Z",
     "start_time": "2025-07-22T12:59:36.192801Z"
    }
   },
   "source": "# Setting up CUDA devices for training and inference\ntraining_env = os.environ.copy()\ntraining_env[\"CUDA_VISIBLE_DEVICES\"] = \"4,5,6,7\"\n\ninference_env = os.environ.copy()\ninference_env[\"CUDA_VISIBLE_DEVICES\"] = \"6,7\"",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9014fd1c-a15d-4496-a09b-c875b602d249",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": "TRAIN_ARGS = [\n    \"torchrun\",\n    \"--nproc_per_node=4\",\n    \"--rdzv_backend=c10d\",\n    \"--rdzv_endpoint=127.0.0.1:29500\",\n    TRAIN_SCRIPT_ALPACA,\n    \"--model_name_or_path\", BASE_MODEL_ALPACA_PATH,\n    \"--data_path\", CUSTOM_DATA_PATH,\n    \"--bf16\", \"True\",\n    \"--per_device_train_batch_size\", \"2\",\n    \"--per_device_eval_batch_size\", \"2\",\n    \"--gradient_accumulation_steps\", \"16\",\n    \"--eval_strategy\", \"no\",\n    \"--save_strategy\", \"steps\",\n    \"--save_steps\", \"2000\",\n    \"--save_total_limit\", \"1\",\n    \"--weight_decay\", \"0.0\",\n    \"--warmup_ratio\", \"0.03\",\n    \"--lr_scheduler_type\", \"cosine\",\n    \"--logging_steps\", \"1\",\n    \"--fsdp\", \"full_shard auto_wrap\",\n    \"--fsdp_transformer_layer_cls_to_wrap\", \"LlamaDecoderLayer\",\n    \"--tf32\", \"True\",\n    \"--overwrite_output_dir\",\n]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0490c42-5bba-48c4-93ce-8bc2efe7a4e3",
   "metadata": {
    "trusted": false
   },
   "outputs": [],
   "source": [
    "if MODEL_NAME == \"alpaca-fine-tuned\":\n",
    "    # Model fine-tuning\n",
    "    BEST_EPOCHS = 10\n",
    "    BEST_LR      = 2e-5\n",
    "    best_name    = f\"e{BEST_EPOCHS}_lr{BEST_LR:.0e}\"\n",
    "    CONDA_BIN = \"/opt/anaconda3/condabin/conda\"\n",
    "\n",
    "    train_cmd = (\n",
    "            [CONDA_BIN, \"run\", \"-n\", \"alpaca\"]\n",
    "            + TRAIN_ARGS\n",
    "            + [\n",
    "                \"--num_train_epochs\", str(BEST_EPOCHS),\n",
    "                \"--learning_rate\",      str(BEST_LR),\n",
    "                \"--output_dir\",         FINE_TUNED_WEIGHTS_PATH,\n",
    "                \"--run_name\",           best_name,\n",
    "            ]\n",
    "    )\n",
    "    print(f\"\\n→ TRAIN {best_name}\")\n",
    "    subprocess.run(train_cmd, check=True, env=training_env)"
   ]
  },
  {
   "cell_type": "code",
   "id": "cc800089-4e50-4fbd-9a1b-eaae0f06b99e",
   "metadata": {
    "trusted": false,
    "ExecuteTime": {
     "end_time": "2025-07-22T13:03:26.466956Z",
     "start_time": "2025-07-22T13:01:13.651009Z"
    }
   },
   "source": [
    "# Model inferencing\n",
    "N_RUNS = 1\n",
    "inference_results = []\n",
    "CONDA_BIN = \"/opt/anaconda3/condabin/conda\"\n",
    "\n",
    "for run_idx in range(1, N_RUNS + 1):\n",
    "    run_id = f\"{MODEL_NAME}_run{run_idx}\"\n",
    "    pm_cmd = [\n",
    "        CONDA_BIN, \"run\", \"-n\", \"archetype\",\n",
    "        \"--no-capture-output\",\n",
    "        \"papermill\",\n",
    "        \"custom_inference.ipynb\",\n",
    "        f\"{PAPERMILL_ROOT}/test_out_{run_id}.ipynb\",\n",
    "        \"-p\", \"tune\", run_id,\n",
    "        \"-p\", \"model_name\", MODEL_NAME,\n",
    "        \"-p\", \"sherlock_path\", SHERLOCK_PATH\n",
    "    ]\n",
    "    print(f\"→ INFERENCE {run_id}\")\n",
    "    subprocess.run(pm_cmd, check=True, env=inference_env)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ INFERENCE llama_run1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/omadbek/.conda/envs/archetype/lib/python3.11/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n",
      "Input Notebook:  custom_inference.ipynb\n",
      "Output Notebook: /home/omadbek/projects/ArcheType/papermill_notebooks/test_out_llama_run1.ipynb\n",
      "Executing:   0%|          | 0/44 [00:00<?, ?cell/s]Executing notebook with kernel: python3\n",
      "Executing: 100%|██████████| 44/44 [02:11<00:00,  2.99s/cell]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Hyperparameter tuning of the alpaca-fine-tuned model\n",
    "\"\"\"\n",
    "#  Your hyperparameter grid\n",
    "GRID = [\n",
    "    (3, 1e-5),\n",
    "    (5, 1e-5),\n",
    "    (8, 1e-5),\n",
    "    (10, 1e-5),\n",
    "    (15, 1e-5),\n",
    "    (18, 1e-5),\n",
    "    (20, 1e-5),\n",
    "    (3, 2e-5),\n",
    "    (5, 2e-5),\n",
    "    (8, 2e-5),\n",
    "    (10, 2e-5),\n",
    "    (15, 2e-5),\n",
    "    (18, 2e-5),\n",
    "    (20, 2e-5),\n",
    "]\n",
    "\n",
    "results = []\n",
    "CONDA_BIN = \"/opt/anaconda3/condabin/conda\"\n",
    "\n",
    "for epochs, lr in GRID:\n",
    "    name   = f\"epoch{epochs}_lr{lr:.0e}\"\n",
    "\n",
    "    # ────────────────────────────────────────────────────────────\n",
    "\n",
    "    # 1) TRAIN under alpaca env\n",
    "    train_cmd = (\n",
    "        [CONDA_BIN, \"run\", \"-n\", \"alpaca\"]\n",
    "        + TRAIN_ARGS\n",
    "        + [\n",
    "            \"--num_train_epochs\", str(epochs),\n",
    "            \"--learning_rate\",      str(lr),\n",
    "            \"--output_dir\",         FINE_TUNED_WEIGHTS_PATH,\n",
    "            \"--run_name\",           name,\n",
    "        ]\n",
    "    )\n",
    "    print(f\"\\n→ TRAIN {name}\")\n",
    "    result = subprocess.run(train_cmd, check=True, env=training_env)\n",
    "\n",
    "\n",
    "    # ────────────────────────────────────────────────────────────\n",
    "    # 2) INFERENCE via Papermill under archetype env\n",
    "    pm_cmd = [\n",
    "        CONDA_BIN, \"run\", \"-n\", \"archetype\",\n",
    "        \"--no-capture-output\",\n",
    "        \"papermill\",\n",
    "        \"custom_inference.ipynb\",\n",
    "        f\"{PAPERMILL_ROOT}/test_out_{name}.ipynb\",\n",
    "        \"-p\", \"tune\", str(name),\n",
    "        \"-p\", \"model_name\", \"alpaca-fine-tuned\",\n",
    "        \"-p\" \"sherlock_path\", SHERLOCK_PATH,\n",
    "    ]\n",
    "    print(f\"→ INFERENCE {name}\")\n",
    "    subprocess.run(pm_cmd, check=True, env=inference_env)\n",
    "\n",
    "# ────────────────────────────────────────────────────────────────\n",
    "print(\"\\n=== EVERYTHING IS DONE! ===\")\n",
    "\"\"\""
   ],
   "id": "3b6c3394272a2f37"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
